{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samer-glitch/TADP-Enhancing-Trustworthiness-in-Federated-Learning-Through-Provenance-Driven-Governance/blob/main/Governance_%2B_Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpYqYCc1XRe0",
        "outputId": "c26064ab-9f0a-4505-e6ad-2b961c676dc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Loading Fashion-MNIST...\n",
            "âœ… F-MNIST loaded: train=60000, test=10000\n",
            "ðŸ”§ Creating Non-IID clients (Dirichlet Î±=0.5)\n",
            "   Client 0: 11403 samples â†’ {np.int64(0): np.int64(379), np.int64(1): np.int64(20), np.int64(2): np.int64(13), np.int64(3): np.int64(1605), np.int64(4): np.int64(752), np.int64(5): np.int64(4718), np.int64(6): np.int64(1781), np.int64(7): np.int64(18), np.int64(8): np.int64(3), np.int64(9): np.int64(2114)}\n",
            "   Client 1: 13670 samples â†’ {np.int64(0): np.int64(150), np.int64(1): np.int64(44), np.int64(2): np.int64(3), np.int64(3): np.int64(2872), np.int64(4): np.int64(271), np.int64(5): np.int64(185), np.int64(6): np.int64(2334), np.int64(7): np.int64(2548), np.int64(8): np.int64(5106), np.int64(9): np.int64(157)}\n",
            "   Client 2: 13192 samples â†’ {np.int64(0): np.int64(284), np.int64(1): np.int64(3953), np.int64(2): np.int64(1132), np.int64(3): np.int64(16), np.int64(4): np.int64(2713), np.int64(5): np.int64(95), np.int64(6): np.int64(1514), np.int64(7): np.int64(1401), np.int64(8): np.int64(2), np.int64(9): np.int64(2082)}\n",
            "   Client 3: 7330 samples â†’ {np.int64(0): np.int64(3232), np.int64(1): np.int64(1249), np.int64(2): np.int64(544), np.int64(3): np.int64(1), np.int64(4): np.int64(1590), np.int64(5): np.int64(312), np.int64(6): np.int64(24), np.int64(7): np.int64(14), np.int64(8): np.int64(316), np.int64(9): np.int64(48)}\n",
            "   Client 4: 4986 samples â†’ {np.int64(0): np.int64(1236), np.int64(1): np.int64(415), np.int64(2): np.int64(59), np.int64(3): np.int64(1012), np.int64(4): np.int64(155), np.int64(5): np.int64(618), np.int64(6): np.int64(41), np.int64(7): np.int64(2), np.int64(8): np.int64(171), np.int64(9): np.int64(1277)}\n",
            "   Client 5: 9419 samples â†’ {np.int64(0): np.int64(719), np.int64(1): np.int64(319), np.int64(2): np.int64(4249), np.int64(3): np.int64(494), np.int64(4): np.int64(519), np.int64(5): np.int64(72), np.int64(6): np.int64(306), np.int64(7): np.int64(2017), np.int64(8): np.int64(402), np.int64(9): np.int64(322)}\n",
            "âœ… Clients created.\n",
            "\n",
            "ðŸ“Š Static PScore values:\n",
            "   Client 0: 4.05\n",
            "   Client 1: 3.92\n",
            "   Client 2: 3.94\n",
            "   Client 3: 3.03\n",
            "   Client 4: 3.28\n",
            "   Client 5: 2.83\n",
            "\n",
            "ðŸ”’ Static governance threshold from 30th percentile: 3.155\n",
            "\n",
            "ðŸŽ¯ FedAvg\n",
            "  Round 1\n",
            "     Client 0 acc=0.921\n",
            "     Client 1 acc=0.926\n",
            "     Client 2 acc=0.886\n",
            "     Client 3 acc=0.938\n",
            "     Client 4 acc=0.912\n",
            "     Client 5 acc=0.889\n",
            "     ðŸŸ¢ Acc=0.6768\n",
            "  Round 2\n",
            "     Client 0 acc=0.907\n",
            "     Client 1 acc=0.949\n",
            "     Client 2 acc=0.891\n",
            "     Client 3 acc=0.947\n",
            "     Client 4 acc=0.949\n",
            "     Client 5 acc=0.899\n",
            "     ðŸŸ¢ Acc=0.8095\n",
            "  Round 3\n",
            "     Client 0 acc=0.947\n",
            "     Client 1 acc=0.961\n",
            "     Client 2 acc=0.906\n",
            "     Client 3 acc=0.953\n",
            "     Client 4 acc=0.955\n",
            "     Client 5 acc=0.933\n",
            "     ðŸŸ¢ Acc=0.8438\n",
            "  Round 4\n",
            "     Client 0 acc=0.952\n",
            "     Client 1 acc=0.961\n",
            "     Client 2 acc=0.932\n",
            "     Client 3 acc=0.950\n",
            "     Client 4 acc=0.972\n",
            "     Client 5 acc=0.929\n",
            "     ðŸŸ¢ Acc=0.8787\n",
            "  Round 5\n",
            "     Client 0 acc=0.960\n",
            "     Client 1 acc=0.966\n",
            "     Client 2 acc=0.942\n",
            "     Client 3 acc=0.975\n",
            "     Client 4 acc=0.977\n",
            "     Client 5 acc=0.948\n",
            "     ðŸŸ¢ Acc=0.8836\n",
            "\n",
            "ðŸŽ¯ FedProx (mu=0.01)\n",
            "  Round 1\n",
            "     Client 0 acc=0.883\n",
            "     Client 1 acc=0.918\n",
            "     Client 2 acc=0.837\n",
            "     Client 3 acc=0.925\n",
            "     Client 4 acc=0.915\n",
            "     Client 5 acc=0.850\n",
            "     ðŸŸ¢ Acc=0.7331\n",
            "  Round 2\n",
            "     Client 0 acc=0.908\n",
            "     Client 1 acc=0.925\n",
            "     Client 2 acc=0.846\n",
            "     Client 3 acc=0.922\n",
            "     Client 4 acc=0.909\n",
            "     Client 5 acc=0.874\n",
            "     ðŸŸ¢ Acc=0.7716\n",
            "  Round 3\n",
            "     Client 0 acc=0.908\n",
            "     Client 1 acc=0.935\n",
            "     Client 2 acc=0.888\n",
            "     Client 3 acc=0.945\n",
            "     Client 4 acc=0.932\n",
            "     Client 5 acc=0.894\n",
            "     ðŸŸ¢ Acc=0.8044\n",
            "  Round 4\n",
            "     Client 0 acc=0.912\n",
            "     Client 1 acc=0.948\n",
            "     Client 2 acc=0.860\n",
            "     Client 3 acc=0.946\n",
            "     Client 4 acc=0.945\n",
            "     Client 5 acc=0.891\n",
            "     ðŸŸ¢ Acc=0.8365\n",
            "  Round 5\n",
            "     Client 0 acc=0.935\n",
            "     Client 1 acc=0.949\n",
            "     Client 2 acc=0.899\n",
            "     Client 3 acc=0.949\n",
            "     Client 4 acc=0.954\n",
            "     Client 5 acc=0.919\n",
            "     ðŸŸ¢ Acc=0.8319\n",
            "\n",
            "ðŸŽ¯ Median\n",
            "  Round 1\n",
            "     Client 0 acc=0.910\n",
            "     Client 1 acc=0.937\n",
            "     Client 2 acc=0.891\n",
            "     Client 3 acc=0.935\n",
            "     Client 4 acc=0.931\n",
            "     Client 5 acc=0.886\n",
            "     ðŸŸ¢ Acc=0.4943\n",
            "  Round 2\n",
            "     Client 0 acc=0.923\n",
            "     Client 1 acc=0.942\n",
            "     Client 2 acc=0.899\n",
            "     Client 3 acc=0.946\n",
            "     Client 4 acc=0.929\n",
            "     Client 5 acc=0.903\n",
            "     ðŸŸ¢ Acc=0.7865\n",
            "  Round 3\n",
            "     Client 0 acc=0.934\n",
            "     Client 1 acc=0.955\n",
            "     Client 2 acc=0.916\n",
            "     Client 3 acc=0.956\n",
            "     Client 4 acc=0.952\n",
            "     Client 5 acc=0.926\n",
            "     ðŸŸ¢ Acc=0.8286\n",
            "  Round 4\n",
            "     Client 0 acc=0.928\n",
            "     Client 1 acc=0.957\n",
            "     Client 2 acc=0.921\n",
            "     Client 3 acc=0.951\n",
            "     Client 4 acc=0.953\n",
            "     Client 5 acc=0.927\n",
            "     ðŸŸ¢ Acc=0.8510\n",
            "  Round 5\n",
            "     Client 0 acc=0.949\n",
            "     Client 1 acc=0.963\n",
            "     Client 2 acc=0.929\n",
            "     Client 3 acc=0.963\n",
            "     Client 4 acc=0.959\n",
            "     Client 5 acc=0.924\n",
            "     ðŸŸ¢ Acc=0.8779\n",
            "\n",
            "ðŸŽ¯ Krum\n",
            "  Round 1\n",
            "     Client 0 acc=0.908\n",
            "     Client 1 acc=0.939\n",
            "     Client 2 acc=0.874\n",
            "     Client 3 acc=0.933\n",
            "     Client 4 acc=0.921\n",
            "     Client 5 acc=0.887\n",
            "     ðŸŸ¢ Krum chose client ~4\n",
            "     ðŸŸ¢ Acc=0.6862\n",
            "  Round 2\n",
            "     Client 0 acc=0.923\n",
            "     Client 1 acc=0.945\n",
            "     Client 2 acc=0.892\n",
            "     Client 3 acc=0.938\n",
            "     Client 4 acc=0.945\n",
            "     Client 5 acc=0.881\n",
            "     ðŸŸ¢ Krum chose client ~4\n",
            "     ðŸŸ¢ Acc=0.7052\n",
            "  Round 3\n",
            "     Client 0 acc=0.911\n",
            "     Client 1 acc=0.945\n",
            "     Client 2 acc=0.894\n",
            "     Client 3 acc=0.953\n",
            "     Client 4 acc=0.960\n",
            "     Client 5 acc=0.905\n",
            "     ðŸŸ¢ Krum chose client ~4\n",
            "     ðŸŸ¢ Acc=0.7091\n",
            "  Round 4\n",
            "     Client 0 acc=0.934\n",
            "     Client 1 acc=0.953\n",
            "     Client 2 acc=0.903\n",
            "     Client 3 acc=0.952\n",
            "     Client 4 acc=0.960\n",
            "     Client 5 acc=0.908\n",
            "     ðŸŸ¢ Krum chose client ~4\n",
            "     ðŸŸ¢ Acc=0.7006\n",
            "  Round 5\n",
            "     Client 0 acc=0.943\n",
            "     Client 1 acc=0.955\n",
            "     Client 2 acc=0.902\n",
            "     Client 3 acc=0.956\n",
            "     Client 4 acc=0.970\n",
            "     Client 5 acc=0.918\n",
            "     ðŸŸ¢ Krum chose client ~4\n",
            "     ðŸŸ¢ Acc=0.7244\n",
            "\n",
            "ðŸŽ¯ Power-of-Choice (top-3 acc)\n",
            "  Round 1\n",
            "     Client 0 acc=0.908\n",
            "     Client 1 acc=0.931\n",
            "     Client 2 acc=0.886\n",
            "     Client 3 acc=0.903\n",
            "     Client 4 acc=0.919\n",
            "     Client 5 acc=0.884\n",
            "     Selected clients: [1, 4, 0]\n",
            "     ðŸŸ¢ Acc=0.5948\n",
            "  Round 2\n",
            "     Client 0 acc=0.932\n",
            "     Client 1 acc=0.953\n",
            "     Client 2 acc=0.894\n",
            "     Client 3 acc=0.936\n",
            "     Client 4 acc=0.951\n",
            "     Client 5 acc=0.901\n",
            "     Selected clients: [1, 4, 3]\n",
            "     ðŸŸ¢ Acc=0.7815\n",
            "  Round 3\n",
            "     Client 0 acc=0.943\n",
            "     Client 1 acc=0.957\n",
            "     Client 2 acc=0.919\n",
            "     Client 3 acc=0.953\n",
            "     Client 4 acc=0.959\n",
            "     Client 5 acc=0.913\n",
            "     Selected clients: [4, 1, 3]\n",
            "     ðŸŸ¢ Acc=0.8035\n",
            "  Round 4\n",
            "     Client 0 acc=0.948\n",
            "     Client 1 acc=0.964\n",
            "     Client 2 acc=0.922\n",
            "     Client 3 acc=0.963\n",
            "     Client 4 acc=0.967\n",
            "     Client 5 acc=0.932\n",
            "     Selected clients: [4, 1, 3]\n",
            "     ðŸŸ¢ Acc=0.8173\n",
            "  Round 5\n",
            "     Client 0 acc=0.947\n",
            "     Client 1 acc=0.973\n",
            "     Client 2 acc=0.930\n",
            "     Client 3 acc=0.944\n",
            "     Client 4 acc=0.974\n",
            "     Client 5 acc=0.921\n",
            "     Selected clients: [4, 1, 0]\n",
            "     ðŸŸ¢ Acc=0.7965\n",
            "\n",
            "ðŸŽ¯ PScore-Weighted FedAvg (all clients, no gate)\n",
            "  Round 1\n",
            "     Client 0 acc=0.890\n",
            "     Client 1 acc=0.938\n",
            "     Client 2 acc=0.884\n",
            "     Client 3 acc=0.941\n",
            "     Client 4 acc=0.927\n",
            "     Client 5 acc=0.892\n",
            "     ðŸŸ¢ Acc=0.6883\n",
            "  Round 2\n",
            "     Client 0 acc=0.939\n",
            "     Client 1 acc=0.954\n",
            "     Client 2 acc=0.918\n",
            "     Client 3 acc=0.956\n",
            "     Client 4 acc=0.946\n",
            "     Client 5 acc=0.919\n",
            "     ðŸŸ¢ Acc=0.7844\n",
            "  Round 3\n",
            "     Client 0 acc=0.942\n",
            "     Client 1 acc=0.961\n",
            "     Client 2 acc=0.919\n",
            "     Client 3 acc=0.966\n",
            "     Client 4 acc=0.956\n",
            "     Client 5 acc=0.926\n",
            "     ðŸŸ¢ Acc=0.8368\n",
            "  Round 4\n",
            "     Client 0 acc=0.958\n",
            "     Client 1 acc=0.966\n",
            "     Client 2 acc=0.919\n",
            "     Client 3 acc=0.964\n",
            "     Client 4 acc=0.966\n",
            "     Client 5 acc=0.946\n",
            "     ðŸŸ¢ Acc=0.8592\n",
            "  Round 5\n",
            "     Client 0 acc=0.963\n",
            "     Client 1 acc=0.973\n",
            "     Client 2 acc=0.944\n",
            "     Client 3 acc=0.974\n",
            "     Client 4 acc=0.971\n",
            "     Client 5 acc=0.949\n",
            "     ðŸŸ¢ Acc=0.8715\n",
            "\n",
            "ðŸŽ¯ PScore-Weighted FedAvg (all clients, with 2 warm-up rounds)\n",
            "  Round 1 [warm-up]\n",
            "     Client 0 acc=0.891\n",
            "     Client 1 acc=0.933\n",
            "     Client 2 acc=0.899\n",
            "     Client 3 acc=0.914\n",
            "     Client 4 acc=0.916\n",
            "     Client 5 acc=0.888\n",
            "     ðŸŸ¢ Acc=0.6868\n",
            "  Round 2 [warm-up]\n",
            "     Client 0 acc=0.924\n",
            "     Client 1 acc=0.937\n",
            "     Client 2 acc=0.908\n",
            "     Client 3 acc=0.946\n",
            "     Client 4 acc=0.929\n",
            "     Client 5 acc=0.913\n",
            "     ðŸŸ¢ Acc=0.7958\n",
            "  Round 3 [pscore-weighted]\n",
            "     Client 0 acc=0.941\n",
            "     Client 1 acc=0.963\n",
            "     Client 2 acc=0.919\n",
            "     Client 3 acc=0.967\n",
            "     Client 4 acc=0.956\n",
            "     Client 5 acc=0.935\n",
            "     ðŸŸ¢ Acc=0.8227\n",
            "  Round 4 [pscore-weighted]\n",
            "     Client 0 acc=0.956\n",
            "     Client 1 acc=0.968\n",
            "     Client 2 acc=0.931\n",
            "     Client 3 acc=0.970\n",
            "     Client 4 acc=0.966\n",
            "     Client 5 acc=0.925\n",
            "     ðŸŸ¢ Acc=0.8534\n",
            "  Round 5 [pscore-weighted]\n",
            "     Client 0 acc=0.955\n",
            "     Client 1 acc=0.966\n",
            "     Client 2 acc=0.942\n",
            "     Client 3 acc=0.970\n",
            "     Client 4 acc=0.976\n",
            "     Client 5 acc=0.950\n",
            "     ðŸŸ¢ Acc=0.8548\n",
            "\n",
            "ðŸŽ¯ Static PScore Gate (hard gate + PScore-weighted FedAvg)\n",
            "   Threshold=3.155 â†’ accepted: [0, 1, 2, 4]\n",
            "  Round 1\n",
            "     Client 0 acc=0.918\n",
            "     Client 1 acc=0.926\n",
            "     Client 2 acc=0.878\n",
            "     Client 4 acc=0.923\n",
            "     ðŸŸ¢ Acc=0.4562\n",
            "  Round 2\n",
            "     Client 0 acc=0.932\n",
            "     Client 1 acc=0.943\n",
            "     Client 2 acc=0.910\n",
            "     Client 4 acc=0.939\n",
            "     ðŸŸ¢ Acc=0.7461\n",
            "  Round 3\n",
            "     Client 0 acc=0.951\n",
            "     Client 1 acc=0.960\n",
            "     Client 2 acc=0.914\n",
            "     Client 4 acc=0.960\n",
            "     ðŸŸ¢ Acc=0.8078\n",
            "  Round 4\n",
            "     Client 0 acc=0.954\n",
            "     Client 1 acc=0.965\n",
            "     Client 2 acc=0.934\n",
            "     Client 4 acc=0.969\n",
            "     ðŸŸ¢ Acc=0.8018\n",
            "  Round 5\n",
            "     Client 0 acc=0.955\n",
            "     Client 1 acc=0.973\n",
            "     Client 2 acc=0.945\n",
            "     Client 4 acc=0.976\n",
            "     ðŸŸ¢ Acc=0.8408\n",
            "\n",
            "ðŸŽ¯ Dynamic PScore-v3 (warm-up + soft down-weighting)\n",
            "   Static threshold=3.155\n",
            "   High-provenance clients: [0, 1, 2, 4]\n",
            "   Low-provenance clients (penalized): [3, 5]\n",
            "  Round 1 [warm-up]\n",
            "     Client 0 acc=0.922\n",
            "     Client 1 acc=0.928\n",
            "     Client 2 acc=0.890\n",
            "     Client 3 acc=0.923\n",
            "     Client 4 acc=0.913\n",
            "     Client 5 acc=0.882\n",
            "     ðŸŸ¢ Acc=0.7141\n",
            "  Round 2 [warm-up]\n",
            "     Client 0 acc=0.933\n",
            "     Client 1 acc=0.934\n",
            "     Client 2 acc=0.914\n",
            "     Client 3 acc=0.950\n",
            "     Client 4 acc=0.944\n",
            "     Client 5 acc=0.918\n",
            "     ðŸŸ¢ Acc=0.7907\n",
            "  Round 3 [gov-weighted]\n",
            "     Client 0 acc=0.939\n",
            "     Client 1 acc=0.955\n",
            "     Client 2 acc=0.922\n",
            "     Client 3 acc=0.955\n",
            "     Client 4 acc=0.959\n",
            "     Client 5 acc=0.928\n",
            "     ðŸŸ¢ Acc=0.8108\n",
            "  Round 4 [gov-weighted]\n",
            "     Client 0 acc=0.950\n",
            "     Client 1 acc=0.964\n",
            "     Client 2 acc=0.933\n",
            "     Client 3 acc=0.957\n",
            "     Client 4 acc=0.953\n",
            "     Client 5 acc=0.931\n",
            "     ðŸŸ¢ Acc=0.8297\n",
            "  Round 5 [gov-weighted]\n",
            "     Client 0 acc=0.956\n",
            "     Client 1 acc=0.966\n",
            "     Client 2 acc=0.939\n",
            "     Client 3 acc=0.960\n",
            "     Client 4 acc=0.967\n",
            "     Client 5 acc=0.939\n",
            "     ðŸŸ¢ Acc=0.8588\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ“Š FINAL RESULTS â€” Fashion-MNIST (Governance + Robust FL, Medium Pipeline)\n",
            "====================================================================================================\n",
            "                  Scenario  Final Accuracy  Final F1-Score  Final Recall  Final AUC-ROC  Total Training Time (s)  Total Energy (kWh)  Total CO2 (kg)  Total Communication (MB)  Selected Clients  Trained Clients  Avg PScore Selected\n",
            "                    FedAvg          0.8836          0.8831        0.8836         0.9920                1534.7043              0.0426          0.0171                   15.0000                 6                6               3.5083\n",
            "                    Median          0.8779          0.8752        0.8779         0.9902                1607.6872              0.0447          0.0179                   15.0000                 6                6               3.5083\n",
            "   PScoreWeightedFedAvgAll          0.8715          0.8714        0.8715         0.9922                1551.1180              0.0431          0.0172                   15.0000                 6                6               3.5083\n",
            "           DynamicPScoreV3          0.8588          0.8572        0.8588         0.9906                1563.6618              0.0434          0.0174                   15.0000                 6                6               3.7975\n",
            "PScoreWeightedFedAvgWarmup          0.8548          0.8510        0.8548         0.9913                1566.2729              0.0435          0.0174                   15.0000                 6                6               3.5083\n",
            "          StaticPScoreGate          0.8408          0.8383        0.8408         0.9902                1123.2493              0.0312          0.0125                   10.0000                 4                4               3.7975\n",
            "                   FedProx          0.8319          0.8300        0.8319         0.9873                1661.4742              0.0462          0.0185                   15.0000                 6                6               3.5083\n",
            "           Power-of-Choice          0.7965          0.7673        0.7965         0.9855                1570.1542              0.0436          0.0174                    7.5000                 3                6               3.7500\n",
            "                      Krum          0.7244          0.6706        0.7244         0.9742                1600.4909              0.0445          0.0178                   15.0000                 1                6               3.5083\n",
            "\n",
            "ðŸ’¾ Saved results to 'fmnist_governance_results_medium_pipeline.csv'\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Sequential Federated Learning with Governance â€” Fashion-MNIST (Medium Pipeline)\n",
        "\n",
        "Taxonomy:\n",
        "\n",
        "  No governance:\n",
        "    - FedAvg\n",
        "    - FedProx\n",
        "\n",
        "  Robust FL:\n",
        "    - Median\n",
        "    - Krum\n",
        "\n",
        "  Data-driven selection:\n",
        "    - Power-of-Choice (top-k based on local acc)\n",
        "\n",
        "  Soft / hard governance:\n",
        "    - PScoreWeightedFedAvgAll       (all clients, PScore-weighted FedAvg)\n",
        "    - PScoreWeightedFedAvgWarmup    (warm-up + PScore-weighted)\n",
        "    - StaticPScoreGate              (hard gate + PScore-weighted FedAvg)\n",
        "    - DynamicPScoreV3               (warm-up + soft down-weighting, no filtering)\n",
        "\n",
        "Outputs per scenario:\n",
        "    - Final Accuracy, F1, Recall, AUC-ROC (macro)\n",
        "    - Total Training Time (s)\n",
        "    - Total Energy (kWh)\n",
        "    - Total CO2 (kg)\n",
        "    - Total Communication (MB)\n",
        "    - Selected Clients, Trained Clients\n",
        "    - Avg PScore Selected\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# ============================================================\n",
        "#  GLOBAL CONFIG (FAST VERSION)\n",
        "# ============================================================\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# Fast config for FMNIST\n",
        "N_CLIENTS = 6\n",
        "N_ROUNDS = 5           # reduced rounds\n",
        "LOCAL_EPOCHS = 1       # single local epoch\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "\n",
        "ALPHA_DIRICHLET = 0.5  # non-IID strength\n",
        "\n",
        "DEVICE_POWER_KW = 0.1\n",
        "CO2_PER_KWH = 0.4\n",
        "MODEL_SIZE_MB = 0.5    # small CNN, lower comms\n",
        "\n",
        "# Robust / selection params\n",
        "POC_TOP_K = 3           # Power-of-Choice (top-k by local acc)\n",
        "KRUM_F_BYZANTINE = 1    # assumed Byzantine clients for Krum\n",
        "\n",
        "# Static PScore gate\n",
        "GOVERNANCE_PERCENTILE = 30.0  # 30th percentile threshold\n",
        "\n",
        "# Dynamic PScore-v3 (soft down-weighting)\n",
        "DYN_WARMUP_ROUNDS = 2   # fewer warm-up rounds for speed\n",
        "DYN_ALPHA_PROV = 0.7\n",
        "DYN_LOW_PENALTY = 0.5\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  UTILS\n",
        "# ============================================================\n",
        "\n",
        "def set_global_seed(seed: int = RANDOM_STATE):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def estimate_energy_kwh(t_s: float) -> float:\n",
        "    return DEVICE_POWER_KW * (t_s / 3600.0)\n",
        "\n",
        "\n",
        "def estimate_co2_kg(kwh: float) -> float:\n",
        "    return kwh * CO2_PER_KWH\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  DATA LOADING â€” FASHION-MNIST\n",
        "# ============================================================\n",
        "\n",
        "def load_fmnist() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        X_train: (N_train, 1, 28, 28), float32 in [0,1]\n",
        "        X_test:  (N_test, 1, 28, 28), float32 in [0,1]\n",
        "        y_train, y_test: int64 labels [0..9]\n",
        "    \"\"\"\n",
        "    print(\"ðŸ“Š Loading Fashion-MNIST...\")\n",
        "\n",
        "    train_set = datasets.FashionMNIST(\n",
        "        root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=None\n",
        "    )\n",
        "    test_set = datasets.FashionMNIST(\n",
        "        root=\"./data\",\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=None\n",
        "    )\n",
        "\n",
        "    # train_set.data: (60000, 28, 28), uint8\n",
        "    X_train = train_set.data.numpy().astype(np.float32) / 255.0\n",
        "    X_train = np.expand_dims(X_train, 1)  # (N, 1, 28, 28)\n",
        "    y_train = train_set.targets.numpy().astype(np.int64)\n",
        "\n",
        "    X_test = test_set.data.numpy().astype(np.float32) / 255.0\n",
        "    X_test = np.expand_dims(X_test, 1)\n",
        "    y_test = test_set.targets.numpy().astype(np.int64)\n",
        "\n",
        "    print(f\"âœ… F-MNIST loaded: train={X_train.shape[0]}, test={X_test.shape[0]}\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  NON-IID DIRICHLET CLIENT SPLITTER\n",
        "# ============================================================\n",
        "\n",
        "def create_dirichlet_clients(\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    n_clients: int,\n",
        "    alpha: float,\n",
        ") -> List[Dict]:\n",
        "\n",
        "    print(f\"ðŸ”§ Creating Non-IID clients (Dirichlet Î±={alpha})\")\n",
        "    n_classes = len(np.unique(y))\n",
        "    idx_by_class = [np.where(y == k)[0] for k in range(n_classes)]\n",
        "\n",
        "    client_indices = [[] for _ in range(n_clients)]\n",
        "\n",
        "    for k in range(n_classes):\n",
        "        idx_k = idx_by_class[k]\n",
        "        np.random.shuffle(idx_k)\n",
        "\n",
        "        proportions = np.random.dirichlet(alpha * np.ones(n_clients))\n",
        "        counts = (proportions * len(idx_k)).astype(int)\n",
        "\n",
        "        diff = len(idx_k) - counts.sum()\n",
        "        for i in range(abs(diff)):\n",
        "            counts[i % n_clients] += int(np.sign(diff))\n",
        "\n",
        "        start = 0\n",
        "        for cid in range(n_clients):\n",
        "            end = min(start + counts[cid], len(idx_k))\n",
        "            client_indices[cid].extend(idx_k[start:end])\n",
        "            start = end\n",
        "\n",
        "    clients = []\n",
        "    for cid in range(n_clients):\n",
        "        idx = np.array(client_indices[cid])\n",
        "        Xc, yc = X[idx], y[idx]\n",
        "        dist = dict(zip(*np.unique(yc, return_counts=True)))\n",
        "        print(f\"   Client {cid}: {len(yc)} samples â†’ {dist}\")\n",
        "        clients.append({\"id\": cid, \"X\": Xc, \"y\": yc})\n",
        "\n",
        "    print(\"âœ… Clients created.\\n\")\n",
        "    return clients\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  MODEL â€” SMALL CNN FOR FASHION-MNIST\n",
        "# ============================================================\n",
        "\n",
        "class FMNISTNet(nn.Module):\n",
        "    def __init__(self, n_classes: int = 10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),   # 14x14\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),   # 7x7\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 7 * 7, 256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(256, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def init_global_model() -> nn.Module:\n",
        "    return FMNISTNet(n_classes=10).to(DEVICE)\n",
        "\n",
        "\n",
        "def get_model_params(model: nn.Module) -> Dict[str, torch.Tensor]:\n",
        "    return {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "\n",
        "def set_model_params(model: nn.Module, params: Dict[str, torch.Tensor]):\n",
        "    model.load_state_dict(params, strict=True)\n",
        "\n",
        "\n",
        "def average_state_dicts(\n",
        "    param_list: List[Dict[str, torch.Tensor]],\n",
        "    weights: List[float],\n",
        ") -> Dict[str, torch.Tensor]:\n",
        "    weights = np.array(weights, dtype=float)\n",
        "    weights = weights / (weights.sum() + 1e-12)\n",
        "\n",
        "    avg = {}\n",
        "    for k in param_list[0].keys():\n",
        "        stacked = torch.stack([\n",
        "            p[k].float() * float(w) for p, w in zip(param_list, weights)\n",
        "        ])\n",
        "        avg[k] = stacked.sum(dim=0)\n",
        "    return avg\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  LOCAL TRAINING (FEDAVG) + FEDPROX\n",
        "# ============================================================\n",
        "\n",
        "CRITERION = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def local_train(\n",
        "    global_model: nn.Module,\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        ") -> Tuple[Dict[str, torch.Tensor], float, float]:\n",
        "\n",
        "    if X.shape[0] == 0:\n",
        "        return get_model_params(global_model), 0.0, 0.0\n",
        "\n",
        "    local_model = FMNISTNet(n_classes=10).to(DEVICE)\n",
        "    local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    optimizer = optim.Adam(local_model.parameters(), lr=LR)\n",
        "\n",
        "    X_tensor = torch.from_numpy(X).float().to(DEVICE)\n",
        "    y_tensor = torch.from_numpy(y.astype(np.int64)).long().to(DEVICE)\n",
        "\n",
        "    n_samples = X_tensor.shape[0]\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    start = time.time()\n",
        "    local_model.train()\n",
        "\n",
        "    for _ in range(LOCAL_EPOCHS):\n",
        "        np.random.shuffle(indices)\n",
        "        for s in range(0, n_samples, BATCH_SIZE):\n",
        "            e = min(s + BATCH_SIZE, n_samples)\n",
        "            idx = indices[s:e]\n",
        "            xb = X_tensor[idx]\n",
        "            yb = y_tensor[idx]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = local_model(xb)\n",
        "            loss = CRITERION(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    local_model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = local_model(X_tensor)\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "    acc = accuracy_score(y, preds)\n",
        "    return get_model_params(local_model), train_time, acc\n",
        "\n",
        "\n",
        "def local_train_fedprox(\n",
        "    global_model: nn.Module,\n",
        "    X: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    mu: float,\n",
        ") -> Tuple[Dict[str, torch.Tensor], float, float]:\n",
        "\n",
        "    if X.shape[0] == 0:\n",
        "        return get_model_params(global_model), 0.0, 0.0\n",
        "\n",
        "    local_model = FMNISTNet(n_classes=10).to(DEVICE)\n",
        "    local_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    global_params = {k: v.detach().clone() for k, v in global_model.state_dict().items()}\n",
        "    optimizer = optim.Adam(local_model.parameters(), lr=LR)\n",
        "\n",
        "    X_tensor = torch.from_numpy(X).float().to(DEVICE)\n",
        "    y_tensor = torch.from_numpy(y.astype(np.int64)).long().to(DEVICE)\n",
        "\n",
        "    n_samples = X_tensor.shape[0]\n",
        "    indices = np.arange(n_samples)\n",
        "\n",
        "    start = time.time()\n",
        "    local_model.train()\n",
        "\n",
        "    for _ in range(LOCAL_EPOCHS):\n",
        "        np.random.shuffle(indices)\n",
        "        for s in range(0, n_samples, BATCH_SIZE):\n",
        "            e = min(s + BATCH_SIZE, n_samples)\n",
        "            idx = indices[s:e]\n",
        "            xb = X_tensor[idx]\n",
        "            yb = y_tensor[idx]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = local_model(xb)\n",
        "            base_loss = CRITERION(logits, yb)\n",
        "\n",
        "            prox_term = 0.0\n",
        "            for name, param in local_model.named_parameters():\n",
        "                prox_term = prox_term + torch.sum(\n",
        "                    (param - global_params[name].to(DEVICE)) ** 2\n",
        "                )\n",
        "\n",
        "            loss = base_loss + (mu / 2.0) * prox_term\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    train_time = time.time() - start\n",
        "\n",
        "    local_model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = local_model(X_tensor)\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "    acc = accuracy_score(y, preds)\n",
        "    return get_model_params(local_model), train_time, acc\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  GLOBAL EVALUATION\n",
        "# ============================================================\n",
        "\n",
        "def evaluate_global_model(\n",
        "    model: nn.Module,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        ") -> Dict[str, float]:\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_t = torch.from_numpy(X_test).float().to(DEVICE)\n",
        "        logits = model(X_t)\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = np.argmax(probs, axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds, average=\"macro\")\n",
        "    rec = recall_score(y_test, preds, average=\"macro\")\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(y_test, probs, multi_class=\"ovr\")\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"recall\": rec, \"auc\": auc}\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  ROBUST AGGREGATION HELPERS (MEDIAN, KRUM)\n",
        "# ============================================================\n",
        "\n",
        "def median_aggregate(param_list: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
        "    out = {}\n",
        "    for k in param_list[0].keys():\n",
        "        stacked = torch.stack([p[k].float() for p in param_list])  # [C, ...]\n",
        "        median_vals = torch.median(stacked, dim=0).values\n",
        "        out[k] = median_vals\n",
        "    return out\n",
        "\n",
        "\n",
        "def _param_distance(p1: Dict[str, torch.Tensor], p2: Dict[str, torch.Tensor]) -> float:\n",
        "    dist = 0.0\n",
        "    for k in p1.keys():\n",
        "        diff = (p1[k].float() - p2[k].float()).view(-1)\n",
        "        dist += torch.sum(diff * diff).item()\n",
        "    return dist\n",
        "\n",
        "\n",
        "def krum_aggregate(param_list: List[Dict[str, torch.Tensor]], f_byz: int) -> Tuple[Dict[str, torch.Tensor], int]:\n",
        "    \"\"\"\n",
        "    Classical Krum:\n",
        "      - For each client update i, compute sum of distances to its\n",
        "        closest (m - f_byz - 2) other updates.\n",
        "      - Choose update with minimal score.\n",
        "    \"\"\"\n",
        "    m = len(param_list)\n",
        "    if m <= 2 * f_byz + 2:\n",
        "        avg = average_state_dicts(param_list, [1.0] * m)\n",
        "        return avg, -1\n",
        "\n",
        "    dists = np.zeros((m, m), dtype=float)\n",
        "    for i in range(m):\n",
        "        for j in range(i + 1, m):\n",
        "            d = _param_distance(param_list[i], param_list[j])\n",
        "            dists[i, j] = dists[j, i] = d\n",
        "\n",
        "    scores = []\n",
        "    for i in range(m):\n",
        "        others = np.delete(dists[i], i)\n",
        "        nb_closest = m - f_byz - 2\n",
        "        score_i = np.sum(np.partition(others, nb_closest)[:nb_closest])\n",
        "        scores.append(score_i)\n",
        "\n",
        "    winner = int(np.argmin(scores))\n",
        "    return param_list[winner], winner\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  PSCORE UTILITIES\n",
        "# ============================================================\n",
        "\n",
        "def get_static_pscores(n_clients: int) -> List[float]:\n",
        "    # Same demonstration vector as Adult pipeline\n",
        "    base = [\n",
        "        4.05, 3.92, 3.94, 3.03, 3.28,\n",
        "        2.83, 2.39, 1.58, 2.37, 1.51\n",
        "    ]\n",
        "    return base[:n_clients]\n",
        "\n",
        "\n",
        "def compute_governance_threshold(pscores: List[float], percentile: float) -> float:\n",
        "    arr = np.array(pscores, dtype=float)\n",
        "    return float(np.percentile(arr, percentile))\n",
        "\n",
        "\n",
        "def minmax_normalize_pscores(pscores: List[float]) -> np.ndarray:\n",
        "    ps = np.array(pscores, dtype=float)\n",
        "    p_min, p_max = ps.min(), ps.max()\n",
        "    p_rng = p_max - p_min if p_max > p_min else 1.0\n",
        "    return (ps - p_min) / p_rng\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  FEDERATED SCENARIOS\n",
        "# ============================================================\n",
        "\n",
        "def run_fedavg(clients, X_test, y_test, pscores):\n",
        "    print(\"ðŸŽ¯ FedAvg\")\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params, weights = [], []\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "            local_params.append(params)\n",
        "            weights.append(len(c[\"y\"]))\n",
        "\n",
        "        avg = average_state_dicts(local_params, weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"FedAvg\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(clients),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean(pscores)),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_fedprox(clients, X_test, y_test, pscores, mu: float = 0.01):\n",
        "    print(\"\\nðŸŽ¯ FedProx (mu={})\".format(mu))\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params, weights = [], []\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train_fedprox(global_model, c[\"X\"], c[\"y\"], mu)\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "            local_params.append(params)\n",
        "            weights.append(len(c[\"y\"]))\n",
        "\n",
        "        avg = average_state_dicts(local_params, weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"FedProx\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(clients),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean(pscores)),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_median(clients, X_test, y_test, pscores):\n",
        "    print(\"\\nðŸŽ¯ Median\")\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params = []\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "            local_params.append(params)\n",
        "\n",
        "        agg = median_aggregate(local_params)\n",
        "        set_model_params(global_model, agg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"Median\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(clients),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean(pscores)),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_krum(clients, X_test, y_test, pscores):\n",
        "    print(\"\\nðŸŽ¯ Krum\")\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "    chosen_counts = [0] * len(clients)\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params = []\n",
        "\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "            local_params.append(params)\n",
        "\n",
        "        agg, chosen = krum_aggregate(local_params, KRUM_F_BYZANTINE)\n",
        "        if chosen >= 0:\n",
        "            chosen_counts[chosen] += 1\n",
        "            print(f\"     ðŸŸ¢ Krum chose client ~{chosen}\")\n",
        "        else:\n",
        "            print(\"     ðŸŸ¢ Fallback to FedAvg\")\n",
        "\n",
        "        set_model_params(global_model, agg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"Krum\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": 1,\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean(pscores)),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_power_of_choice(clients, X_test, y_test, pscores):\n",
        "    print(\"\\nðŸŽ¯ Power-of-Choice (top-{} acc)\".format(POC_TOP_K))\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "    last_selected = []\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params, weights, accs = [], [], []\n",
        "\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "            local_params.append(params)\n",
        "            weights.append(len(c[\"y\"]))\n",
        "            accs.append(acc)\n",
        "\n",
        "        accs = np.array(accs)\n",
        "        top_idx = np.argsort(-accs)[:POC_TOP_K]\n",
        "        last_selected = top_idx.tolist()\n",
        "        print(f\"     Selected clients: {last_selected}\")\n",
        "\n",
        "        sel_params = [local_params[i] for i in top_idx]\n",
        "        sel_weights = [weights[i] for i in top_idx]\n",
        "\n",
        "        avg = average_state_dicts(sel_params, sel_weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * POC_TOP_K * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"Power-of-Choice\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(last_selected),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean([pscores[i] for i in last_selected])),\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  PSCORE-WEIGHTED FEDAVG (ALL CLIENTS, NO GATE)\n",
        "# ============================================================\n",
        "\n",
        "def run_pscore_weighted_fedavg_all(clients, X_test, y_test, pscores):\n",
        "    print(\"\\nðŸŽ¯ PScore-Weighted FedAvg (all clients, no gate)\")\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "\n",
        "    ps_norm = minmax_normalize_pscores(pscores)\n",
        "    f_ps = 0.5 + 1.0 * ps_norm  # [0.5, 1.5]\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params, weights = [], []\n",
        "\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "\n",
        "            eff_w = len(c[\"y\"]) * float(f_ps[cid])\n",
        "            local_params.append(params)\n",
        "            weights.append(eff_w)\n",
        "\n",
        "        avg = average_state_dicts(local_params, weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"PScoreWeightedFedAvgAll\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(clients),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean(pscores)),\n",
        "    }\n",
        "\n",
        "\n",
        "def run_pscore_weighted_fedavg_warmup(clients, X_test, y_test, pscores, warmup_rounds: int = 2):\n",
        "    print(\"\\nðŸŽ¯ PScore-Weighted FedAvg (all clients, with {} warm-up rounds)\".format(warmup_rounds))\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "\n",
        "    ps_norm = minmax_normalize_pscores(pscores)\n",
        "    f_ps = 0.5 + 1.0 * ps_norm\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        mode = \"warm-up\" if r <= warmup_rounds else \"pscore-weighted\"\n",
        "        print(f\"  Round {r} [{mode}]\")\n",
        "\n",
        "        local_params, weights = [], []\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "\n",
        "            if r <= warmup_rounds:\n",
        "                eff_w = len(c[\"y\"])\n",
        "            else:\n",
        "                eff_w = len(c[\"y\"]) * float(f_ps[cid])\n",
        "\n",
        "            local_params.append(params)\n",
        "            weights.append(eff_w)\n",
        "\n",
        "        avg = average_state_dicts(local_params, weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"PScoreWeightedFedAvgWarmup\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(clients),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean(pscores)),\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  STATIC PSCORE GATE (HARD GATE + PSCORE-WEIGHTED)\n",
        "# ============================================================\n",
        "\n",
        "def run_static_pscore_gate(clients, X_test, y_test, pscores, t_gov: float):\n",
        "    print(\"\\nðŸŽ¯ Static PScore Gate (hard gate + PScore-weighted FedAvg)\")\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    accepted_ids = [i for i, s in enumerate(pscores) if s >= t_gov]\n",
        "    print(f\"   Threshold={t_gov:.3f} â†’ accepted: {accepted_ids}\")\n",
        "\n",
        "    active = [c for c in clients if c[\"id\"] in accepted_ids]\n",
        "    total_t = 0.0\n",
        "\n",
        "    if len(active) == 0:\n",
        "        print(\"   âš ï¸ No clients above threshold; falling back to FedAvg.\")\n",
        "        return run_fedavg(clients, X_test, y_test, pscores)\n",
        "\n",
        "    ps_norm = minmax_normalize_pscores(pscores)\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        print(f\"  Round {r}\")\n",
        "        local_params, weights = [], []\n",
        "\n",
        "        for c in active:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "\n",
        "            eff_w = len(c[\"y\"]) * (0.5 + 1.0 * ps_norm[cid])\n",
        "            local_params.append(params)\n",
        "            weights.append(eff_w)\n",
        "\n",
        "        avg = average_state_dicts(local_params, weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(active) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"StaticPScoreGate\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(active),\n",
        "        \"Trained Clients\": len(active),\n",
        "        \"Avg PScore Selected\": float(np.mean([pscores[i] for i in accepted_ids])),\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  DYNAMIC PSCORE-v3 (SOFT PENALTY, NO FILTERING)\n",
        "# ============================================================\n",
        "\n",
        "def run_dynamic_pscore_v3(clients, X_test, y_test, pscores, t_gov: float):\n",
        "    print(\"\\nðŸŽ¯ Dynamic PScore-v3 (warm-up + soft down-weighting)\")\n",
        "\n",
        "    global_model = init_global_model()\n",
        "    total_t = 0.0\n",
        "\n",
        "    ps_norm = minmax_normalize_pscores(pscores)\n",
        "    high_ids = [i for i, s in enumerate(pscores) if s >= t_gov]\n",
        "    low_ids = [i for i, s in enumerate(pscores) if s < t_gov]\n",
        "\n",
        "    print(f\"   Static threshold={t_gov:.3f}\")\n",
        "    print(f\"   High-provenance clients: {high_ids}\")\n",
        "    print(f\"   Low-provenance clients (penalized): {low_ids}\")\n",
        "\n",
        "    for r in range(1, N_ROUNDS + 1):\n",
        "        mode = \"warm-up\" if r <= DYN_WARMUP_ROUNDS else \"gov-weighted\"\n",
        "        print(f\"  Round {r} [{mode}]\")\n",
        "\n",
        "        local_params, weights = [], []\n",
        "        for c in clients:\n",
        "            cid = c[\"id\"]\n",
        "            params, t, acc = local_train(global_model, c[\"X\"], c[\"y\"])\n",
        "            print(f\"     Client {cid} acc={acc:.3f}\")\n",
        "            total_t += t\n",
        "\n",
        "            if r <= DYN_WARMUP_ROUNDS:\n",
        "                eff_w = len(c[\"y\"])\n",
        "            else:\n",
        "                norm_p = ps_norm[cid]\n",
        "                if cid in low_ids:\n",
        "                    norm_p *= DYN_LOW_PENALTY\n",
        "                g_factor = DYN_ALPHA_PROV * norm_p + (1.0 - DYN_ALPHA_PROV)\n",
        "                eff_w = len(c[\"y\"]) * max(g_factor, 1e-3)\n",
        "\n",
        "            local_params.append(params)\n",
        "            weights.append(eff_w)\n",
        "\n",
        "        avg = average_state_dicts(local_params, weights)\n",
        "        set_model_params(global_model, avg)\n",
        "        m = evaluate_global_model(global_model, X_test, y_test)\n",
        "        print(f\"     ðŸŸ¢ Acc={m['accuracy']:.4f}\")\n",
        "\n",
        "    final = evaluate_global_model(global_model, X_test, y_test)\n",
        "    energy = estimate_energy_kwh(total_t)\n",
        "    co2 = estimate_co2_kg(energy)\n",
        "    comm = N_ROUNDS * len(clients) * MODEL_SIZE_MB\n",
        "\n",
        "    return {\n",
        "        \"Scenario\": \"DynamicPScoreV3\",\n",
        "        \"Final Accuracy\": final[\"accuracy\"],\n",
        "        \"Final F1-Score\": final[\"f1\"],\n",
        "        \"Final Recall\": final[\"recall\"],\n",
        "        \"Final AUC-ROC\": final[\"auc\"],\n",
        "        \"Total Training Time (s)\": total_t,\n",
        "        \"Total Energy (kWh)\": energy,\n",
        "        \"Total CO2 (kg)\": co2,\n",
        "        \"Total Communication (MB)\": comm,\n",
        "        \"Selected Clients\": len(clients),\n",
        "        \"Trained Clients\": len(clients),\n",
        "        \"Avg PScore Selected\": float(np.mean([pscores[i] for i in high_ids])),\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "#  MAIN PIPELINE\n",
        "# ============================================================\n",
        "\n",
        "def main():\n",
        "    set_global_seed()\n",
        "\n",
        "    # 1) Load dataset\n",
        "    X_train, X_test, y_train, y_test = load_fmnist()\n",
        "\n",
        "    # 2) Non-IID client splits\n",
        "    clients = create_dirichlet_clients(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        n_clients=N_CLIENTS,\n",
        "        alpha=ALPHA_DIRICHLET,\n",
        "    )\n",
        "\n",
        "    # 3) PScore vector + governance threshold\n",
        "    pscores = get_static_pscores(N_CLIENTS)\n",
        "    print(\"ðŸ“Š Static PScore values:\")\n",
        "    for cid, s in enumerate(pscores):\n",
        "        print(f\"   Client {cid}: {s:.2f}\")\n",
        "    print()\n",
        "\n",
        "    t_gov = compute_governance_threshold(pscores, GOVERNANCE_PERCENTILE)\n",
        "    print(f\"ðŸ”’ Static governance threshold from {GOVERNANCE_PERCENTILE:.0f}th percentile: {t_gov:.3f}\\n\")\n",
        "\n",
        "    # 4) Run baselines + governance variants (medium pipeline)\n",
        "    all_results = []\n",
        "\n",
        "    # No-governance baselines\n",
        "    all_results.append(run_fedavg(clients, X_test, y_test, pscores))\n",
        "    all_results.append(run_fedprox(clients, X_test, y_test, pscores, mu=0.01))\n",
        "\n",
        "    # Robust FL\n",
        "    all_results.append(run_median(clients, X_test, y_test, pscores))\n",
        "    all_results.append(run_krum(clients, X_test, y_test, pscores))\n",
        "\n",
        "    # Data-driven selection\n",
        "    all_results.append(run_power_of_choice(clients, X_test, y_test, pscores))\n",
        "\n",
        "    # Governance-aware variants\n",
        "    all_results.append(run_pscore_weighted_fedavg_all(clients, X_test, y_test, pscores))\n",
        "    all_results.append(run_pscore_weighted_fedavg_warmup(clients, X_test, y_test, pscores, warmup_rounds=DYN_WARMUP_ROUNDS))\n",
        "    all_results.append(run_static_pscore_gate(clients, X_test, y_test, pscores, t_gov))\n",
        "    all_results.append(run_dynamic_pscore_v3(clients, X_test, y_test, pscores, t_gov))\n",
        "\n",
        "    # 5) Final summary\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"ðŸ“Š FINAL RESULTS â€” Fashion-MNIST (Governance + Robust FL, Medium Pipeline)\")\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    df = pd.DataFrame(all_results)\n",
        "\n",
        "    cols_order = [\n",
        "        \"Scenario\",\n",
        "        \"Final Accuracy\",\n",
        "        \"Final F1-Score\",\n",
        "        \"Final Recall\",\n",
        "        \"Final AUC-ROC\",\n",
        "        \"Total Training Time (s)\",\n",
        "        \"Total Energy (kWh)\",\n",
        "        \"Total CO2 (kg)\",\n",
        "        \"Total Communication (MB)\",\n",
        "        \"Selected Clients\",\n",
        "        \"Trained Clients\",\n",
        "        \"Avg PScore Selected\",\n",
        "    ]\n",
        "    cols_order = [c for c in cols_order if c in df.columns]\n",
        "    df = df[cols_order]\n",
        "\n",
        "    if \"Final Accuracy\" in df.columns:\n",
        "        df = df.sort_values(by=[\"Final Accuracy\", \"Scenario\"], ascending=[False, True])\n",
        "\n",
        "    print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
        "\n",
        "    out_csv = \"fmnist_governance_results_medium_pipeline.csv\"\n",
        "    df.to_csv(out_csv, index=False)\n",
        "    print(f\"\\nðŸ’¾ Saved results to '{out_csv}'\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJfJ0PiSHhR9fv29uT3oZD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}